{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg/qS0cH1ZXy+ZgGZw1G6+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharadwaj103/NLP/blob/main/NLP_F_22_08_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w_6Je3UDPCG",
        "outputId": "27ebdcdf-461c-417d-fa27-3c4db875da38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns in DataFrame: ['ID', 'W', 'G', 'R', 'AB', 'H', '1B', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'CS', 'HBP', 'BBHBP', 'SF', 'Outs', 'Outsinplay', 'RA', 'BA', 'OBA', 'SLG', 'OPS']\n",
            "\n",
            "--- Sentence 1: 'The quick brown fox jumps over the lazy dog.' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "The                  DET        det            \n",
            "quick                ADJ        amod           \n",
            "brown                ADJ        amod           \n",
            "fox                  NOUN       nsubj          \n",
            "jumps                VERB       ROOT           \n",
            "over                 ADP        prep           \n",
            "the                  DET        det            \n",
            "lazy                 ADJ        amod           \n",
            "dog                  NOUN       pobj           \n",
            ".                    PUNCT      punct          \n",
            "\n",
            "Nouns: ['fox', 'dog']\n",
            "Verbs: ['jumps']\n",
            "Adjectives: ['quick', 'brown', 'lazy']\n",
            "\n",
            "--- Sentence 2: 'SpaCy is a powerful library for natural language processing.' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "SpaCy                PROPN      nsubj          \n",
            "is                   AUX        ROOT           \n",
            "a                    DET        det            \n",
            "powerful             ADJ        amod           \n",
            "library              NOUN       attr           \n",
            "for                  ADP        prep           \n",
            "natural              ADJ        amod           \n",
            "language             NOUN       compound       \n",
            "processing           NOUN       pobj           \n",
            ".                    PUNCT      punct          \n",
            "\n",
            "Nouns: ['library', 'language', 'processing']\n",
            "Verbs: []\n",
            "Adjectives: ['powerful', 'natural']\n",
            "\n",
            "--- Sentence 3: 'I am learning to code in Python.' ---\n",
            "Token                POS Tag    Dependency     \n",
            "---------------------------------------------\n",
            "I                    PRON       nsubj          \n",
            "am                   AUX        aux            \n",
            "learning             VERB       ROOT           \n",
            "to                   PART       aux            \n",
            "code                 VERB       xcomp          \n",
            "in                   ADP        prep           \n",
            "Python               PROPN      pobj           \n",
            ".                    PUNCT      punct          \n",
            "\n",
            "Nouns: []\n",
            "Verbs: ['learning', 'code']\n",
            "Adjectives: []\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Print available columns to help diagnose KeyError\n",
        "print(\"Available columns in DataFrame:\", df.columns.tolist())\n",
        "\n",
        "# Load the spaCy model\n",
        "# If you don't have it, run this in your terminal:\n",
        "# python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Get the first 5 text entries\n",
        "# You need to replace 'description_x' with an actual text column from your DataFrame.\n",
        "# For example, if you have a column named 'text_column', you would use:\n",
        "# sample_texts = df['text_column'].head().tolist()\n",
        "# Since 'train.csv' does not contain a text column, we'll use some example sentences.\n",
        "sample_texts = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"SpaCy is a powerful library for natural language processing.\",\n",
        "    \"I am learning to code in Python.\"\n",
        "]\n",
        "\n",
        "# Process each text entry\n",
        "for i, text in enumerate(sample_texts):\n",
        "    print(f\"\\n--- Sentence {i+1}: '{text}' ---\")\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Prepare lists to hold the parts of speech\n",
        "    nouns = []\n",
        "    verbs = []\n",
        "    adjectives = []\n",
        "\n",
        "    print(f\"{'Token':<20} {'POS Tag':<10} {'Dependency':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    # Extract and print token details\n",
        "    for token in doc:\n",
        "        print(f\"{token.text:<20} {token.pos_:<10} {token.dep_:<15}\")\n",
        "        if token.pos_ == 'NOUN':\n",
        "            nouns.append(token.text)\n",
        "        elif token.pos_ == 'VERB':\n",
        "            verbs.append(token.text)\n",
        "        elif token.pos_ == 'ADJ':\n",
        "            adjectives.append(token.text)\n",
        "\n",
        "    # Print the extracted parts of speech\n",
        "    print(\"\\nNouns:\", nouns)\n",
        "    print(\"Verbs:\", verbs)\n",
        "    print(\"Adjectives:\", adjectives)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# The list of sentences from your question\n",
        "texts = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "## 1. Find Phone Numbers\n",
        "print(\"--- Found Phone Numbers ---\")\n",
        "\n",
        "# Regex to find different phone number formats present in the text\n",
        "phone_pattern = r'(?:\\+\\d{1,3}[-\\s]?)?\\d{10}|(?:\\+\\d{1,3}[-\\s]?)?\\d{5}[-\\s]?\\d{5}'\n",
        "found_phones = []\n",
        "\n",
        "# Loop through each text to find phone numbers\n",
        "for text in texts:\n",
        "    found_phones.extend(re.findall(phone_pattern, text))\n",
        "\n",
        "# Print the results\n",
        "if found_phones:\n",
        "    for phone in found_phones:\n",
        "        print(phone)\n",
        "else:\n",
        "    print(\"No phone numbers were found.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\") # Separator for clarity\n",
        "\n",
        "## 2. Remove Phone Numbers, Emails, URLs, and Special Characters\n",
        "print(\"--- Cleaned Text ---\")\n",
        "\n",
        "cleaned_texts = []\n",
        "for text in texts:\n",
        "    # Make a copy to modify\n",
        "    clean_text = text\n",
        "\n",
        "    # Remove URLs (e.g., https://example.com)\n",
        "    clean_text = re.sub(r'https?://\\S+', '', clean_text)\n",
        "\n",
        "    # Remove emails (e.g., test@domain.com)\n",
        "    clean_text = re.sub(r'\\S+@\\S+\\.\\S+', '', clean_text)\n",
        "\n",
        "    # Remove phone numbers using the same pattern as above\n",
        "    clean_text = re.sub(phone_pattern, '', clean_text)\n",
        "\n",
        "    # Remove special characters (anything not a letter, number, or space)\n",
        "    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', clean_text)\n",
        "\n",
        "    # Remove extra whitespace (like double spaces) that may result from removal\n",
        "    clean_text = ' '.join(clean_text.split())\n",
        "\n",
        "    cleaned_texts.append(clean_text)\n",
        "\n",
        "# Print the original vs. cleaned text for comparison\n",
        "for i in range(len(texts)):\n",
        "    print(f\"Original: \\\"{texts[i]}\\\"\")\n",
        "    print(f\"Cleaned:  \\\"{cleaned_texts[i]}\\\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJWV6rmTDXEj",
        "outputId": "fd90fd14-37e5-46b4-9d9b-6d29d64c3538"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Found Phone Numbers ---\n",
            "1234567890\n",
            "+91 98765-43210\n",
            "\n",
            "========================================\n",
            "\n",
            "--- Cleaned Text ---\n",
            "Original: \"My phone number is 1234567890 and my email is test@domain.com\"\n",
            "Cleaned:  \"My phone number is and my email is\"\n",
            "\n",
            "Original: \"Visit https://example.com for more info!!!\"\n",
            "Cleaned:  \"Visit for more info\"\n",
            "\n",
            "Original: \"HELLO!!! This is SOOOOO exciting :))\"\n",
            "Cleaned:  \"HELLO This is SOOOOO exciting\"\n",
            "\n",
            "Original: \"Contact us at info@company.org or call +91 98765-43210\"\n",
            "Cleaned:  \"Contact us at or call\"\n",
            "\n",
            "Original: \"Python's regex is very useful!!!  #Coding #Fun\"\n",
            "Cleaned:  \"Pythons regex is very useful Coding Fun\"\n",
            "\n"
          ]
        }
      ]
    }
  ]
}